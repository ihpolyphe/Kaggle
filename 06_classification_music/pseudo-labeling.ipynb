{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIGNATE Student Cup 2021春【予測部門】における解放として有力なkNNと、特長量エンジニアリングについて、以下の記事を参考に学んでいく。\n",
    "# https://signate.jp/competitions/449/discussions/pseudo-labeling-lb06630"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02\n",
      " 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02 1.e+02\n",
      " 1.e+02 8.e+00 1.e+00 1.e+00 1.e+00 1.e+00 1.e+00 1.e+00 1.e+00 1.e+00\n",
      " 1.e+00 1.e-03 1.e+02]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ワーニングの出力をなくして表示をシンプルにするもの？\n",
    "# warnings.simplefilter('ignore', pd.core.common.SettingWithCopyWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "# 今回の分類数。ジャンルの数。\n",
    "N_CLASSES = 11\n",
    "\n",
    "# ファイルのインポート\n",
    "INPUT = Path(\"input\")\n",
    "df_train = pd.read_csv(INPUT / \"train.csv\")\n",
    "df_test = pd.read_csv(INPUT / \"test.csv\")\n",
    "df_sample_sub = pd.read_csv(INPUT / \"sample_submit.csv\", header=None)\n",
    "df_sample_sub.columns = [\"index\", \"genre\"]\n",
    "df_genre_labels = pd.read_csv(INPUT / \"genre_labels.csv\")\n",
    "\n",
    "\n",
    "# trainデータとtestデータをミックスしている。\n",
    "# 特長量エンジニアリングを別々にやるのは面倒なので、ここで合体させて、学習時に分けるようにしていると思われる。賢い。\n",
    "def merge_train_test(df_train, df_test):\n",
    "    if \"genre\" not in df_test.columns.tolist():\n",
    "        df_test[\"genre\"] = -100\n",
    "    res = pd.concat([df_train, df_test])\n",
    "    res.reset_index(inplace=True, drop=True)\n",
    "    return res\n",
    "\n",
    "# 合体させたときにgenre=-100にしているので、それを起点にtrainデータとtestデータを分ける。\n",
    "def split_train_test(df):\n",
    "    df_train = df[df[\"genre\"] != -100]\n",
    "    df_test = df[df[\"genre\"] == -100]\n",
    "    df_train.reset_index(inplace=True, drop=True)\n",
    "    df_test.reset_index(inplace=True, drop=True)\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "# parameters\n",
    "\n",
    "# def lgb_metric(preds, data):  \n",
    "#     pred_labels = preds.reshape(N_CLASSES, -1).argmax(axis=0)\n",
    "#     score = f1_score(data.get_label(), pred_labels, average=\"macro\")\n",
    "#     return \"macro_f1\", score, True\n",
    "\n",
    "# 以下、lightGBMの学習時のパラメータ定義\n",
    "learning_rate = 0.01\n",
    "\n",
    "lgb_params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"num_class\": N_CLASSES,\n",
    "    #\"metric\": \"None\",\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"num_leaves\": 3,\n",
    "    \"min_data_in_leaf\": 40,\n",
    "    #\"colsample_bytree\": 1.0,\n",
    "    #\"feature_fraction\": 1.0,\n",
    "    #\"bagging_freq\": 0,\n",
    "    #\"bagging_fraction\": 1.0,\n",
    "    \"verbosity\": 0,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "#k近傍法のグループ数?\n",
    "knn_n_neighbors = 6\n",
    "\n",
    "\n",
    "# parameters - knn feature weights\n",
    "# 以下、kNNの学習時のパラメータ定義。regionはラベルエンコーディング、その他の量的変数は標準化、それ以外にnanの数も特徴量として使っている。\n",
    "knn_features = [\n",
    "   'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "   'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "   'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "   'region_S', 'region_T', 'region_unknown',\n",
    "   'standardscaled_popularity', 'standardscaled_duration_ms',\n",
    "   'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "   'standardscaled_danceability', 'standardscaled_loudness',\n",
    "   'standardscaled_energy', 'standardscaled_liveness',\n",
    "   'standardscaled_speechiness', 'standardscaled_instrumentalness',\n",
    "   'standardscaled_log_tempo', 'standardscaled_num_nans'\n",
    "]\n",
    "\n",
    "dict_feature_weights = {}\n",
    "\n",
    "# regionの特長量重みを設定。\n",
    "# 以下のように重みを決めていくことができるらしい。\n",
    "# 重みですが、最初に大まかに当たりをつけ(regionは違うものが近傍データとして選ばれないくらい大きめ、popularityも他の特徴より大きめなど)、\n",
    "# 交差検証での精度を見ながら細かい調整をしています。\n",
    "for col in [\n",
    "    'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "    'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "    'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "    'region_S', 'region_T', 'region_unknown'\n",
    "]:\n",
    "    dict_feature_weights[col] = 100.0\n",
    "\n",
    "for col in [\n",
    "    'standardscaled_duration_ms',\n",
    "    'standardscaled_acousticness', 'standardscaled_positiveness',\n",
    "    'standardscaled_danceability', 'standardscaled_loudness',\n",
    "    'standardscaled_energy', 'standardscaled_liveness',\n",
    "    'standardscaled_speechiness', 'standardscaled_instrumentalness'\n",
    "]:\n",
    "    dict_feature_weights[col] = 1.0\n",
    "\n",
    "# popularityは他の特徴よりも大きめに設定。\n",
    "dict_feature_weights[\"standardscaled_popularity\"] = 8.0\n",
    "dict_feature_weights[\"standardscaled_log_tempo\"] = 0.001\n",
    "dict_feature_weights[\"standardscaled_num_nans\"] = 100.0\n",
    "\n",
    "# k近傍法の特徴量重みをnumpy配列に変換。\n",
    "knn_feature_weights = np.array([dict_feature_weights[col] for col in knn_features])\n",
    "print(knn_feature_weights)\n",
    "\n",
    "# train,testデータに対して特長量エンジニアリングを行うため、合体させる。\n",
    "df_main = merge_train_test(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>positiveness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>...</th>\n",
       "      <th>region_L</th>\n",
       "      <th>region_M</th>\n",
       "      <th>region_N</th>\n",
       "      <th>region_O</th>\n",
       "      <th>region_P</th>\n",
       "      <th>region_Q</th>\n",
       "      <th>region_R</th>\n",
       "      <th>region_S</th>\n",
       "      <th>region_T</th>\n",
       "      <th>region_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>201094</td>\n",
       "      <td>0.112811</td>\n",
       "      <td>0.157247</td>\n",
       "      <td>0.187841</td>\n",
       "      <td>-1.884852</td>\n",
       "      <td>0.893918</td>\n",
       "      <td>0.363568</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>69</td>\n",
       "      <td>308493</td>\n",
       "      <td>0.101333</td>\n",
       "      <td>0.346563</td>\n",
       "      <td>0.554444</td>\n",
       "      <td>-5.546495</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>0.193892</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>197225</td>\n",
       "      <td>0.496420</td>\n",
       "      <td>0.265391</td>\n",
       "      <td>0.457642</td>\n",
       "      <td>-9.255670</td>\n",
       "      <td>0.439933</td>\n",
       "      <td>0.217146</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>301092</td>\n",
       "      <td>0.165667</td>\n",
       "      <td>0.245533</td>\n",
       "      <td>0.356578</td>\n",
       "      <td>-5.088788</td>\n",
       "      <td>0.868704</td>\n",
       "      <td>0.377025</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>57</td>\n",
       "      <td>277348</td>\n",
       "      <td>0.190720</td>\n",
       "      <td>0.777578</td>\n",
       "      <td>0.830479</td>\n",
       "      <td>-3.933896</td>\n",
       "      <td>0.650149</td>\n",
       "      <td>0.169323</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  genre  popularity  duration_ms  acousticness  positiveness   \n",
       "0      0     10          11       201094      0.112811      0.157247  \\\n",
       "1      1      8          69       308493      0.101333      0.346563   \n",
       "2      2      3          43       197225      0.496420      0.265391   \n",
       "3      3     10          45       301092      0.165667      0.245533   \n",
       "4      4      3          57       277348      0.190720      0.777578   \n",
       "\n",
       "   danceability  loudness    energy  liveness  ...  region_L  region_M   \n",
       "0      0.187841 -1.884852  0.893918  0.363568  ...     False     False  \\\n",
       "1      0.554444 -5.546495  0.874409  0.193892  ...     False     False   \n",
       "2      0.457642 -9.255670  0.439933  0.217146  ...     False     False   \n",
       "3      0.356578 -5.088788  0.868704  0.377025  ...     False     False   \n",
       "4      0.830479 -3.933896  0.650149  0.169323  ...     False     False   \n",
       "\n",
       "   region_N region_O region_P  region_Q  region_R  region_S  region_T   \n",
       "0     False    False    False     False     False     False     False  \\\n",
       "1     False    False    False     False     False     False     False   \n",
       "2     False    False    False     False     False     False     False   \n",
       "3     False    False    False     False     False     False     False   \n",
       "4     False    False    False     False     False     False     False   \n",
       "\n",
       "   region_unknown  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 動作検証用のおためし。\n",
    "df = df_main.copy()\n",
    "df[\"genre_name\"] = df[\"genre\"].map(dict(df_genre_labels[[\"labels\", \"genre\"]].values))\n",
    "df[\"tempo\"] = df[\"tempo\"].map(lambda x: sum(map(int, x.split(\"-\"))) / 2)\n",
    "df = pd.concat([df, pd.get_dummies(df[\"region\"]).rename(columns={\"unknown\": \"region_unknown\"})], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pseudo_labeling_threshold in [0.95, 0.925, 0.9, 0.875, 0.85, -np.inf]:\n",
    "    #疑似ラベルを使って学習する際の閾値を設定。confidenceがこの閾値を超える場合に、そのラベルを使って学習する。\n",
    "    df = df_main.copy()\n",
    "    \n",
    "    \n",
    "    # feature engineering\n",
    "    # genreのラベル番号からジャンル名に変換している。\n",
    "    df[\"genre_name\"] = df[\"genre\"].map(dict(df_genre_labels[[\"labels\", \"genre\"]].values))\n",
    "    # tempoの値を平均値に変換している。\n",
    "    df[\"tempo\"] = df[\"tempo\"].map(lambda x: sum(map(int, x.split(\"-\"))) / 2)\n",
    "    # regionのone-hotエンコーディング、ついでにunknownの列名を変更している。\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"region\"]).rename(columns={\"unknown\": \"region_unknown\"})], axis=1)\n",
    "\n",
    "\n",
    "    #===================ここまで確認完了。\n",
    "    df[\"num_nans\"] = 0\n",
    "    for col in [\n",
    "        \"acousticness\",\n",
    "        \"positiveness\",\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"liveness\",\n",
    "        \"speechiness\",\n",
    "        \"instrumentalness\",\n",
    "    ]:\n",
    "        df[\"num_nans\"] += df[col].isna()\n",
    "\n",
    "    class CountEncoder:\n",
    "        def fit(self, series):\n",
    "            self.counts = series.groupby(series).count()\n",
    "            return self\n",
    "\n",
    "        def transform(self, series):\n",
    "            return series.map(self.counts).fillna(0)\n",
    "\n",
    "        def fit_transform(self, series):\n",
    "            return self.fit(series).transform(series)\n",
    "    columns_count_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"countenc_\" + col] = CountEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"countenc_\" + col] = np.nan\n",
    "\n",
    "\n",
    "    columns_label_enc = [\"region\"]\n",
    "    for col in columns_count_enc:\n",
    "        df[\"labelenc_\" + col] = LabelEncoder().fit_transform(df[col])\n",
    "        df.loc[df[col].isna().values, \"labelenc_\" + col] = np.nan\n",
    "\n",
    "\n",
    "    class GroupFeatureExtractor:  # 参考: https://signate.jp/competitions/449/discussions/lgbm-baseline-lb06240\n",
    "        EX_TRANS_METHODS = [\"deviation\", \"zscore\"]\n",
    "\n",
    "        def __init__(self, group_key, group_values, agg_methods):\n",
    "            self.group_key = group_key\n",
    "            self.group_values = group_values\n",
    "\n",
    "            self.ex_trans_methods = [m for m in agg_methods if m in self.EX_TRANS_METHODS]\n",
    "            self.agg_methods = [m for m in agg_methods if m not in self.ex_trans_methods]\n",
    "            self.df_agg = None\n",
    "\n",
    "        def fit(self, df_train, y=None):\n",
    "            if not self.agg_methods:\n",
    "                return\n",
    "            dfs = []\n",
    "            for agg_method in self.agg_methods:\n",
    "                if callable(agg_method):\n",
    "                    agg_method_name = agg_method.__name__\n",
    "                else:\n",
    "                    agg_method_name = agg_method\n",
    "                df_agg = (df_train[[self.group_key] + self.group_values].groupby(self.group_key).agg(agg_method))\n",
    "                df_agg.columns = self._get_column_names(agg_method_name)\n",
    "                dfs.append(df_agg)\n",
    "            self.df_agg = pd.concat(dfs, axis=1).reset_index()\n",
    "\n",
    "        def transform(self, df_eval):\n",
    "            key = self.group_key\n",
    "            if self.agg_methods:\n",
    "                df_features = pd.merge(df_eval[[self.group_key]], self.df_agg, on=self.group_key, how=\"left\")\n",
    "            else:\n",
    "                df_features = df_eval[[self.group_key]].copy()\n",
    "            if self.ex_trans_methods:\n",
    "                if \"deviation\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_agg_column_names(\"deviation\")] = df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")\n",
    "                if \"zscore\" in self.ex_trans_methods:\n",
    "                    df_features[self._get_column_names(\"zscore\")] = (df_eval[self.group_values] - df_eval[[key]+self.group_values].groupby(key).transform(\"mean\")) \\\n",
    "                                                                    / (df_eval[[key]+self.group_values].groupby(key).transform(\"std\") + 1e-8)\n",
    "            df_features.drop(self.group_key, axis=1, inplace=True)\n",
    "            return df_features\n",
    "\n",
    "        def _get_column_names(self, method):\n",
    "            return [f\"agg_{method}_{col}_grpby_{self.group_key}\" for col in self.group_values]\n",
    "\n",
    "        def fit_transform(self, df_train, y=None):\n",
    "            self.fit(df_train, y=y)\n",
    "            return self.transform(df_train)   \n",
    "\n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    gfe = GroupFeatureExtractor(\n",
    "        \"region\", \n",
    "        ['popularity', 'duration_ms', 'acousticness', 'positiveness', 'danceability', 'loudness', 'energy', 'liveness', 'speechiness', 'instrumentalness', 'log_tempo'],\n",
    "        [\"zscore\"]\n",
    "    )\n",
    "    df = pd.concat([df, gfe.fit_transform(df)], axis=1)\n",
    "\n",
    "\n",
    "    class KNNFeatureExtractor:\n",
    "        def __init__(self, n_neighbors=5):\n",
    "            self.knn = KNeighborsClassifier(n_neighbors + 1)\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            self.knn.fit(X, y)\n",
    "            self.y = y if isinstance(y, np.ndarray) else np.array(y)\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, is_train_data):\n",
    "            distances, indexes = self.knn.kneighbors(X)\n",
    "            distances = distances[:, 1:] if is_train_data else distances[:, :-1]\n",
    "            indexes = indexes[:, 1:] if is_train_data else indexes[:, :-1]\n",
    "            labels = self.y[indexes]\n",
    "            score_columns = [f\"knn_score_class{c:02d}\" for c in range(N_CLASSES)]\n",
    "            df_knn = pd.DataFrame(\n",
    "                [np.bincount(labels_, distances_, N_CLASSES) for labels_, distances_ in zip(labels, 1.0 / distances)],\n",
    "                columns=score_columns\n",
    "            )\n",
    "            df_knn[\"max_knn_scores\"] = df_knn.max(1)\n",
    "            for col in score_columns:\n",
    "                df_knn[f\"sub_max_knn_scores_{col}\"] = df_knn[\"max_knn_scores\"] - df_knn[col]\n",
    "            for i, col1 in enumerate(score_columns):\n",
    "                for j, col2 in enumerate(score_columns[i+1:], i+1):\n",
    "                    if {i, j} & {8, 10}:\n",
    "                        df_knn[f\"sub_{col1}_{col2}\"] = df_knn[col1] - df_knn[col2]\n",
    "            df_knn[\"sum_knn_scores\"] = df_knn.sum(1)\n",
    "\n",
    "            return df_knn\n",
    "\n",
    "\n",
    "    # feature scaling\n",
    "\n",
    "    df[\"log_tempo\"] = np.log(df[\"tempo\"])\n",
    "    for col in [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'log_tempo', 'num_nans',\n",
    "    ]:\n",
    "        df[\"standardscaled_\" + col] = StandardScaler().fit_transform(df[[col]])[:, 0]\n",
    "\n",
    "\n",
    "\n",
    "    df_train, df_test = split_train_test(df)\n",
    "    target = df_train[\"genre\"]\n",
    "    \n",
    "    \n",
    "    # train\n",
    "    \n",
    "    N_SPLITS = 15\n",
    "    SEED_SKF = 42\n",
    "    np.random.seed(42)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED_SKF)\n",
    "    oof = np.zeros((len(df_train), N_CLASSES))\n",
    "    predictions = np.zeros((len(df_test), N_CLASSES))\n",
    "    df_feature_importance = pd.DataFrame()\n",
    "\n",
    "    features_numerical = [\n",
    "        'popularity', 'duration_ms', 'acousticness',\n",
    "        'positiveness', 'danceability', 'loudness', 'energy', 'liveness',\n",
    "        'speechiness', 'instrumentalness', 'tempo',\n",
    "        'region_A', 'region_B', 'region_C', 'region_D', 'region_E', 'region_F',\n",
    "        'region_G', 'region_H', 'region_I', 'region_J', 'region_K', 'region_L',\n",
    "        'region_M', 'region_N', 'region_O', 'region_P', 'region_Q', 'region_R',\n",
    "        'region_S', 'region_T', 'region_unknown', 'countenc_region',\n",
    "        'num_nans',\n",
    "        'agg_zscore_popularity_grpby_region',\n",
    "        'agg_zscore_duration_ms_grpby_region',\n",
    "        'agg_zscore_acousticness_grpby_region',\n",
    "        'agg_zscore_positiveness_grpby_region',\n",
    "        'agg_zscore_danceability_grpby_region',\n",
    "        'agg_zscore_loudness_grpby_region', 'agg_zscore_energy_grpby_region',\n",
    "        'agg_zscore_liveness_grpby_region',\n",
    "        'agg_zscore_speechiness_grpby_region',\n",
    "        'agg_zscore_instrumentalness_grpby_region',\n",
    "        'agg_zscore_log_tempo_grpby_region',\n",
    "        'knn_score_class00', 'knn_score_class01',\n",
    "        'knn_score_class02', 'knn_score_class03', 'knn_score_class04',\n",
    "        'knn_score_class05', 'knn_score_class06', 'knn_score_class07',\n",
    "        'knn_score_class08', 'knn_score_class09', 'knn_score_class10',\n",
    "        'max_knn_scores',\n",
    "        'sub_max_knn_scores_knn_score_class00',\n",
    "        'sub_max_knn_scores_knn_score_class01',\n",
    "        'sub_max_knn_scores_knn_score_class02',\n",
    "        'sub_max_knn_scores_knn_score_class03',\n",
    "        'sub_max_knn_scores_knn_score_class04',\n",
    "        'sub_max_knn_scores_knn_score_class05',\n",
    "        'sub_max_knn_scores_knn_score_class06',\n",
    "        'sub_max_knn_scores_knn_score_class07',\n",
    "        'sub_max_knn_scores_knn_score_class08',\n",
    "        'sub_max_knn_scores_knn_score_class09',\n",
    "        'sub_max_knn_scores_knn_score_class10',\n",
    "        'sub_knn_score_class00_knn_score_class08',\n",
    "        'sub_knn_score_class00_knn_score_class10',\n",
    "        'sub_knn_score_class01_knn_score_class08',\n",
    "        'sub_knn_score_class01_knn_score_class10',\n",
    "        'sub_knn_score_class02_knn_score_class08',\n",
    "        'sub_knn_score_class02_knn_score_class10',\n",
    "        'sub_knn_score_class03_knn_score_class08',\n",
    "        'sub_knn_score_class03_knn_score_class10',\n",
    "        'sub_knn_score_class04_knn_score_class08',\n",
    "        'sub_knn_score_class04_knn_score_class10',\n",
    "        'sub_knn_score_class05_knn_score_class08',\n",
    "        'sub_knn_score_class05_knn_score_class10',\n",
    "        'sub_knn_score_class06_knn_score_class08',\n",
    "        'sub_knn_score_class06_knn_score_class10',\n",
    "        'sub_knn_score_class07_knn_score_class08',\n",
    "        'sub_knn_score_class07_knn_score_class10',\n",
    "        'sub_knn_score_class08_knn_score_class09',\n",
    "        'sub_knn_score_class08_knn_score_class10',\n",
    "        'sub_knn_score_class09_knn_score_class10',\n",
    "        'sum_knn_scores'\n",
    "    ]\n",
    "    features_categorical = [\"labelenc_region\"]\n",
    "    features = features_numerical + features_categorical\n",
    "\n",
    "    for fold_, (indexes_trn, indexes_val) in enumerate(skf.split(df_train.values, target.values)):\n",
    "        print(f\"------------------------------ fold {fold_} ------------------------------\")\n",
    "\n",
    "        df_trn = df_train.loc[indexes_trn].reset_index(drop=True)\n",
    "        df_val = df_train.loc[indexes_val].reset_index(drop=True)\n",
    "        target_trn = target.loc[indexes_trn].reset_index(drop=True)\n",
    "        target_val = target.loc[indexes_val].reset_index(drop=True)\n",
    "\n",
    "        # make knn features\n",
    "        X = df_trn[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        knn_feature_extractor = KNNFeatureExtractor(knn_n_neighbors).fit(X, target_trn)\n",
    "        df_trn = pd.concat([df_trn, knn_feature_extractor.transform(X, is_train_data=True)], axis=1)\n",
    "        X = df_val[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_val = pd.concat([df_val, knn_feature_extractor.transform(X, is_train_data=False)], axis=1)\n",
    "        X = df_test[knn_features].fillna(0.0).values * knn_feature_weights\n",
    "        df_test_knn_features = knn_feature_extractor.transform(X, is_train_data=False)\n",
    "        for col in df_test_knn_features.columns:\n",
    "            df_test[col] = df_test_knn_features[col]\n",
    "\n",
    "        lgb_train = lgb.Dataset(\n",
    "            df_trn.loc[:, features],\n",
    "            label=target_trn,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "        lgb_valid = lgb.Dataset(\n",
    "            df_val.loc[:, features],\n",
    "            label=target_val,\n",
    "            feature_name=features,\n",
    "            categorical_feature=features_categorical\n",
    "        )\n",
    "\n",
    "        lgb_params[\"learning_rate\"] = learning_rate + np.random.random() * 0.001  # おまじない\n",
    "        num_round = 999999999\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            lgb_train, \n",
    "            num_round, \n",
    "            valid_sets=[lgb_train, lgb_valid], \n",
    "            verbose_eval=300,\n",
    "            early_stopping_rounds=300 if num_round >= 1e8 else None,\n",
    "            fobj=None,\n",
    "            #feval=lgb_metric,\n",
    "        )\n",
    "\n",
    "        # cv\n",
    "        prediction_round = model.best_iteration+150 if num_round >= 1e8 else num_round  # おまじない\n",
    "        oof[indexes_val] = model.predict(df_val[features], num_iteration=prediction_round)\n",
    "\n",
    "        # feature importance\n",
    "        df_fold_importance = pd.DataFrame()\n",
    "        df_fold_importance[\"feature\"] = features\n",
    "        df_fold_importance[\"importance\"] = model.feature_importance()\n",
    "        df_fold_importance[\"fold\"] = fold_\n",
    "        df_feature_importance = pd.concat([df_feature_importance, df_fold_importance], axis=0)\n",
    "\n",
    "        # prediction for test data\n",
    "        predictions += model.predict(df_test[features], num_iteration=prediction_round) / N_SPLITS\n",
    "        print()\n",
    "\n",
    "    \n",
    "    score = f1_score(target, oof.argmax(1), average=\"macro\")\n",
    "    print(\"CV score (not reliable!)\")\n",
    "    print(f\"  f1: {score:8.5f}\")\n",
    "    print()\n",
    "    print(classification_report(target, oof.argmax(1)))\n",
    "    \n",
    "    \n",
    "    df_test[\"prediction\"] = predictions.argmax(1)\n",
    "    df_test[\"confidence\"] = predictions.max(1)\n",
    "    df_test[\"genre\"] = np.where(predictions.max(1) > pseudo_labeling_threshold, predictions.argmax(1), -100)\n",
    "    df = merge_train_test(df_train, df_test)\n",
    "    df_main[\"genre\"] = df_main[\"index\"].map(dict(df[[\"index\", \"genre\"]].values))\n",
    "    print((df_test[\"confidence\"] > pseudo_labeling_threshold).sum(), f\"rows were filled. (confidence>{pseudo_labeling_threshold})\")\n",
    "    print(\"filled test labels:\", np.bincount(df_test[df_test[\"genre\"]!=-100][\"genre\"]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
